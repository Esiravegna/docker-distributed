{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.112.0.5:34622': None,\n",
       " '10.112.1.5:58216': None,\n",
       " '10.112.2.10:39248': None,\n",
       " '10.112.3.5:46249': None,\n",
       " '10.112.4.4:49167': None}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distributed import Client, progress\n",
    "from subprocess import check_call\n",
    "\n",
    "TF_URL = 'https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl'\n",
    "\n",
    "def install_libs():\n",
    "    check_call('pip install'.split() + [TF_URL])\n",
    "    check_call('pip install keras h5py'.split())\n",
    "\n",
    "    \n",
    "install_libs()\n",
    "\n",
    "c = Client('dscheduler:8786')\n",
    "c.run(install_libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "from contextlib import contextmanager\n",
    "import random\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Flatten, merge, Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from dask import delayed, compute\n",
    "from distributed import Client\n",
    "\n",
    "\n",
    "DEFAULT_LOSS = 'cross_entropy'\n",
    "ML_100K_URL = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "ML_100K_FILENAME = Path(ML_100K_URL.rsplit('/', 1)[1])\n",
    "ML_100K_FOLDER = Path('ml-100k')\n",
    "RESULTS_FILENAME = 'results.json'\n",
    "MODEL_FILENAME = 'model.h5'\n",
    "\n",
    "\n",
    "def load_ratings():\n",
    "    if not ML_100K_FILENAME.exists():\n",
    "        print('Downloading %s to %s...' % (ML_100K_URL, ML_100K_FILENAME))\n",
    "        urlretrieve(ML_100K_URL, ML_100K_FILENAME.name)\n",
    "\n",
    "\n",
    "    if not ML_100K_FOLDER.exists():\n",
    "        print('Extracting %s to %s...' % (ML_100K_FILENAME, ML_100K_FOLDER))\n",
    "        ZipFile(ML_100K_FILENAME.name).extractall('.')\n",
    "    return pd.read_csv(ML_100K_FOLDER / 'u.data', sep='\\t',\n",
    "                          names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "all_ratings = load_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(user_input_dim, item_input_dim,\n",
    "               embedding_size=16, hidden_size=64, n_hidden=4,\n",
    "               dropout_embedding=0.3, dropout_hidden=0.3,\n",
    "               optimizer='adam', loss=DEFAULT_LOSS, use_batchnorm=True,\n",
    "               **ignored_args):\n",
    "\n",
    "    user_id_input = Input(shape=[1], name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "\n",
    "    user_embedding = Embedding(output_dim=embedding_size,\n",
    "                               input_dim=user_input_dim,\n",
    "                               input_length=1,\n",
    "                               name='user_embedding')(user_id_input)\n",
    "    item_embedding = Embedding(output_dim=embedding_size,\n",
    "                               input_dim=item_input_dim,\n",
    "                               input_length=1,\n",
    "                               name='item_embedding')(item_id_input)\n",
    "\n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "    input_vecs = merge([user_vecs, item_vecs], mode='concat')\n",
    "    x = Dropout(dropout_embedding)(input_vecs)\n",
    "\n",
    "    for i in range(n_hidden):\n",
    "        x = Dense(hidden_size, activation='relu')(x)\n",
    "        if i < n_hidden - 1:\n",
    "            x = Dropout(dropout_hidden)(x)\n",
    "            if use_batchnorm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "    if loss == 'cross_entropy':\n",
    "        y = Dense(output_dim=5, activation='softmax')(x)\n",
    "        model = Model(input=[user_id_input, item_id_input], output=y)\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    else:\n",
    "        y = Dense(output_dim=1)(x)\n",
    "        model = Model(input=[user_id_input, item_id_input], output=y)\n",
    "        model.compile(optimizer='adam', loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_ci(func, data_args, ci_range=(0.025, 0.975), n_iter=10000,\n",
    "                 random_state=0):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n_samples = data_args[0].shape[0]\n",
    "    results = []\n",
    "    for i in range(n_iter):\n",
    "        # sample n_samples out of n_samples with replacement\n",
    "        idx = rng.randint(0, n_samples - 1, n_samples)\n",
    "        resampled_args = [np.asarray(arg)[idx] for arg in data_args]\n",
    "        results.append(func(*resampled_args))\n",
    "    results = np.sort(results)\n",
    "    return (results[floor(ci_range[0] * n_iter)],\n",
    "            results[ceil(ci_range[1] * n_iter)])\n",
    "\n",
    "@contextmanager\n",
    "def transactional_open(path, mode='wb'):\n",
    "    tmp_path = path.with_name(path.name + '.tmp')\n",
    "    with tmp_path.open(mode=mode) as f:\n",
    "        yield f\n",
    "    tmp_path.rename(path)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def transactional_fname(path):\n",
    "    tmp_path = path.with_name(path.name + '.tmp')\n",
    "    yield str(tmp_path)\n",
    "    tmp_path.rename(path)\n",
    "\n",
    "\n",
    "def _compute_scores(model, prefix, user_id, item_id, rating, loss):\n",
    "    preds = model.predict([user_id, item_id])\n",
    "    preds = preds.argmax(axis=1) + 1 if loss == 'cross_entropy' else preds\n",
    "    mse = mean_squared_error(preds, rating)\n",
    "    mae = mean_absolute_error(preds, rating)\n",
    "    mae_ci_min, mae_ci_max = bootstrap_ci(mean_absolute_error, [preds, rating])\n",
    "    results = {}\n",
    "    results[prefix + '_mse'] = mse\n",
    "    results[prefix + '_mae'] = mae\n",
    "    results[prefix + '_mae_ci_min'] = mae_ci_min\n",
    "    results[prefix + '_mae_ci_max'] = mae_ci_max\n",
    "    return results, preds\n",
    "\n",
    "\n",
    "def evaluate_one(all_ratings, **kwargs):\n",
    "    # Create a single threaded TF session for this Python thread:\n",
    "    # parallelism is leveraged at a coarser level with dask\n",
    "    session = tf.Session(\n",
    "        # graph=tf.Graph(),\n",
    "        config=tf.ConfigProto(intra_op_parallelism_threads=1))\n",
    "\n",
    "    with session.as_default():\n",
    "        # graph-level deterministic weights init\n",
    "        tf.set_random_seed(0)\n",
    "        _evaluate_one(all_ratings, **kwargs)\n",
    "\n",
    "\n",
    "def _evaluate_one(all_ratings, **kwargs):\n",
    "    params = DEFAULT_PARAMS.copy()\n",
    "    params.update(kwargs)\n",
    "    params_digest = joblib.hash(params)\n",
    "\n",
    "    results = params.copy()\n",
    "    results['digest'] = params_digest\n",
    "    results_folder = Path('/') / 'mnt' / 'results'\n",
    "    results_folder.mkdir(exist_ok=True)\n",
    "    folder = results_folder.joinpath(params_digest)\n",
    "    folder.mkdir(exist_ok=True)\n",
    "    if len(list(folder.glob(\"*/results.json\"))) == 4:\n",
    "        print('Skipping')\n",
    "\n",
    "    split_idx = params.get('split_idx', 0)\n",
    "    print(\"Evaluating model on split #%d:\" % split_idx)\n",
    "    pprint(params)\n",
    "\n",
    "    all_ratings = load_ratings()\n",
    "    ratings_train, ratings_test = train_test_split(\n",
    "        all_ratings, test_size=0.2, random_state=split_idx)\n",
    "    max_user_id = all_ratings['user_id'].max()\n",
    "    max_item_id = all_ratings['item_id'].max()\n",
    "\n",
    "    user_id_train = ratings_train['user_id']\n",
    "    item_id_train = ratings_train['item_id']\n",
    "    rating_train = ratings_train['rating']\n",
    "\n",
    "    user_id_test = ratings_test['user_id']\n",
    "    item_id_test = ratings_test['item_id']\n",
    "    rating_test = ratings_test['rating']\n",
    "\n",
    "    loss = params.get('loss', DEFAULT_LOSS)\n",
    "    if loss == 'cross_entropy':\n",
    "        target_train = rating_train - 1\n",
    "    else:\n",
    "        target_train = rating_train\n",
    "\n",
    "    model = make_model(max_user_id + 1, max_item_id + 1, **params)\n",
    "    results['model_size'] = sum(w.size for w in model.get_weights())\n",
    "    nb_epoch = 5\n",
    "    epochs = 0\n",
    "    for i in range(4):\n",
    "        epochs += nb_epoch\n",
    "        t0 = time()\n",
    "        model.fit([user_id_train, item_id_train], target_train,\n",
    "                  batch_size=params['batch_size'],\n",
    "                  nb_epoch=nb_epoch, shuffle=True, verbose=False)\n",
    "        epoch_duration = (time() - t0) / nb_epoch\n",
    "        train_scores, train_preds = _compute_scores(\n",
    "            model, 'train', user_id_train, item_id_train, rating_train, loss)\n",
    "        results.update(train_scores)\n",
    "        test_scores, test_preds = _compute_scores(\n",
    "            model, 'test', user_id_test, item_id_test, rating_test, loss)\n",
    "        results.update(test_scores)\n",
    "\n",
    "        results['epoch_duration'] = epoch_duration\n",
    "        results['epochs'] = epochs\n",
    "\n",
    "        subfolder = folder.joinpath(\"%03d\" % epochs)\n",
    "        subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "        # Transactional results saving to avoid file corruption on ctrl-c\n",
    "        results_filepath = subfolder.joinpath(RESULTS_FILENAME)\n",
    "        with transactional_open(results_filepath, mode='w') as f:\n",
    "            json.dump(results, f)\n",
    "\n",
    "        model_filepath = subfolder.joinpath(MODEL_FILENAME)\n",
    "        with transactional_fname(model_filepath) as fname:\n",
    "            model.save(fname)\n",
    "\n",
    "        # Save predictions and true labels to be able to recompute new scores\n",
    "        # later\n",
    "        with transactional_open(subfolder / 'test_preds.npy', mode='wb') as f:\n",
    "            np.save(f, test_preds)\n",
    "        with transactional_open(subfolder / 'train_preds.npy', mode='wb') as f:\n",
    "            np.save(f, test_preds)\n",
    "        with transactional_open(subfolder / 'ratings.npy', mode='wb') as f:\n",
    "            np.save(f, rating_test)\n",
    "\n",
    "    return params_digest\n",
    "\n",
    "\n",
    "def _model_complexity_proxy(params):\n",
    "    # Quick approximation of the number of tunable parameter to rank models\n",
    "    # by increasing complexity\n",
    "    embedding_size = params['embedding_size']\n",
    "    n_hidden = params['n_hidden']\n",
    "    if n_hidden == 0:\n",
    "        return embedding_size * 2\n",
    "    else:\n",
    "        hidden_size = params['hidden_size']\n",
    "        return (2 * embedding_size * hidden_size +\n",
    "                (n_hidden - 1) * hidden_size ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ratings = load_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = dict(\n",
    "    embedding_size=16,\n",
    "    hidden_size=64,\n",
    "    n_hidden=4,\n",
    "    dropout_embedding=0.3,\n",
    "    dropout_hidden=0.3,\n",
    "    use_batchnorm=True,\n",
    "    loss=DEFAULT_LOSS,\n",
    "    optimizer='adam',\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "\n",
    "COMMON_SEARCH_SPACE = dict(\n",
    "    embedding_size=[16, 32, 64, 128],\n",
    "    dropout_embedding=[0, 0.2, 0.5],\n",
    "    dropout_hidden=[0, 0.2, 0.5],\n",
    "    use_batchnorm=[True, False],\n",
    "    loss=['mse', 'mae', 'cross_entropy'],\n",
    "    batch_size=[16, 32, 64, 128],\n",
    ")\n",
    "\n",
    "SEARCH_SPACE = [\n",
    "    dict(n_hidden=[0], **COMMON_SEARCH_SPACE),\n",
    "    dict(n_hidden=[1, 2, 3, 4, 5],\n",
    "         hidden_size=[32, 64, 128, 256, 512],\n",
    "         **COMMON_SEARCH_SPACE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = Client('dscheduler:8786').restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n_params = 500\n",
    "all_combinations = list(ParameterGrid(SEARCH_SPACE))\n",
    "random.Random(seed).shuffle(all_combinations)\n",
    "sampled_params = all_combinations[:n_params]\n",
    "sampled_params.sort(key=_model_complexity_proxy)\n",
    "evaluations = []\n",
    "for params in sampled_params:\n",
    "    for split_idx in range(3):\n",
    "        evaluations.append(delayed(evaluate_one)(\n",
    "                all_ratings, split_idx=split_idx, **params))\n",
    "all_results = c.compute(evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "progress(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout_embedding</th>\n",
       "      <th>dropout_hidden</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_mae_ci_max</th>\n",
       "      <th>test_mae_ci_min</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mae_ci_max</th>\n",
       "      <th>train_mae_ci_min</th>\n",
       "      <th>use_batchnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>14.264563</td>\n",
       "      <td>64</td>\n",
       "      <td>mae</td>\n",
       "      <td>100769</td>\n",
       "      <td>4</td>\n",
       "      <td>0.705675</td>\n",
       "      <td>0.715066</td>\n",
       "      <td>0.696186</td>\n",
       "      <td>0.644559</td>\n",
       "      <td>0.649075</td>\n",
       "      <td>0.640063</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>110.402148</td>\n",
       "      <td>256</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>302437</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.695550</td>\n",
       "      <td>0.650412</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.645200</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>54.605125</td>\n",
       "      <td>64</td>\n",
       "      <td>mae</td>\n",
       "      <td>185281</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707273</td>\n",
       "      <td>0.716730</td>\n",
       "      <td>0.697811</td>\n",
       "      <td>0.655483</td>\n",
       "      <td>0.660003</td>\n",
       "      <td>0.650928</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>36.983516</td>\n",
       "      <td>64</td>\n",
       "      <td>mae</td>\n",
       "      <td>96609</td>\n",
       "      <td>3</td>\n",
       "      <td>0.708352</td>\n",
       "      <td>0.717835</td>\n",
       "      <td>0.698841</td>\n",
       "      <td>0.525622</td>\n",
       "      <td>0.529929</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>109.767029</td>\n",
       "      <td>256</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>299365</td>\n",
       "      <td>4</td>\n",
       "      <td>0.708500</td>\n",
       "      <td>0.719450</td>\n",
       "      <td>0.697350</td>\n",
       "      <td>0.626675</td>\n",
       "      <td>0.631763</td>\n",
       "      <td>0.621550</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>24.741096</td>\n",
       "      <td>128</td>\n",
       "      <td>mae</td>\n",
       "      <td>80433</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709085</td>\n",
       "      <td>0.718462</td>\n",
       "      <td>0.699818</td>\n",
       "      <td>0.626380</td>\n",
       "      <td>0.630724</td>\n",
       "      <td>0.622030</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>16.200403</td>\n",
       "      <td>128</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>93029</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711450</td>\n",
       "      <td>0.722350</td>\n",
       "      <td>0.700450</td>\n",
       "      <td>0.609675</td>\n",
       "      <td>0.614862</td>\n",
       "      <td>0.604425</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>55.015294</td>\n",
       "      <td>32</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>175589</td>\n",
       "      <td>4</td>\n",
       "      <td>0.711550</td>\n",
       "      <td>0.722600</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.587337</td>\n",
       "      <td>0.592375</td>\n",
       "      <td>0.582350</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>46.894833</td>\n",
       "      <td>32</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>174789</td>\n",
       "      <td>3</td>\n",
       "      <td>0.712600</td>\n",
       "      <td>0.723050</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.633075</td>\n",
       "      <td>0.623212</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>11.395346</td>\n",
       "      <td>128</td>\n",
       "      <td>mae</td>\n",
       "      <td>62897</td>\n",
       "      <td>2</td>\n",
       "      <td>0.712825</td>\n",
       "      <td>0.721628</td>\n",
       "      <td>0.704040</td>\n",
       "      <td>0.627447</td>\n",
       "      <td>0.631495</td>\n",
       "      <td>0.623340</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>41.996300</td>\n",
       "      <td>64</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>44469</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.724450</td>\n",
       "      <td>0.702150</td>\n",
       "      <td>0.649513</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.644150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>11.431713</td>\n",
       "      <td>32</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>89477</td>\n",
       "      <td>4</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>0.725250</td>\n",
       "      <td>0.702700</td>\n",
       "      <td>0.619050</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>0.613850</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "      <td>22.884539</td>\n",
       "      <td>64</td>\n",
       "      <td>mae</td>\n",
       "      <td>176449</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713918</td>\n",
       "      <td>0.722605</td>\n",
       "      <td>0.705077</td>\n",
       "      <td>0.637722</td>\n",
       "      <td>0.641817</td>\n",
       "      <td>0.633498</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>8.765865</td>\n",
       "      <td>256</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>51765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714050</td>\n",
       "      <td>0.725150</td>\n",
       "      <td>0.702850</td>\n",
       "      <td>0.651012</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>0.645625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>32</td>\n",
       "      <td>8.523760</td>\n",
       "      <td>32</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>87365</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714150</td>\n",
       "      <td>0.724950</td>\n",
       "      <td>0.703400</td>\n",
       "      <td>0.625225</td>\n",
       "      <td>0.630337</td>\n",
       "      <td>0.620088</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batch_size  dropout_embedding  dropout_hidden  embedding_size  \\\n",
       "1335         128                0.5             0.0              32   \n",
       "1623          16                0.5             0.2              32   \n",
       "711           32                0.5             0.5              64   \n",
       "1374          32                0.2             0.0              32   \n",
       "544           16                0.5             0.2              32   \n",
       "1115          64                0.2             0.2              16   \n",
       "724           64                0.5             0.0              32   \n",
       "1826          32                0.5             0.0              64   \n",
       "1725          32                0.0             0.5              64   \n",
       "827          128                0.2             0.0              16   \n",
       "1077          32                0.5             0.2              16   \n",
       "831          128                0.5             0.0              32   \n",
       "1265          64                0.5             0.2              64   \n",
       "1589         128                0.5             0.2              16   \n",
       "696          128                0.2             0.5              32   \n",
       "\n",
       "      epoch_duration  hidden_size           loss  model_size  n_hidden  \\\n",
       "1335       14.264563           64            mae      100769         4   \n",
       "1623      110.402148          256  cross_entropy      302437         4   \n",
       "711        54.605125           64            mae      185281         3   \n",
       "1374       36.983516           64            mae       96609         3   \n",
       "544       109.767029          256  cross_entropy      299365         4   \n",
       "1115       24.741096          128            mae       80433         3   \n",
       "724        16.200403          128  cross_entropy       93029         1   \n",
       "1826       55.015294           32  cross_entropy      175589         4   \n",
       "1725       46.894833           32  cross_entropy      174789         3   \n",
       "827        11.395346          128            mae       62897         2   \n",
       "1077       41.996300           64  cross_entropy       44469         1   \n",
       "831        11.431713           32  cross_entropy       89477         4   \n",
       "1265       22.884539           64            mae      176449         1   \n",
       "1589        8.765865          256  cross_entropy       51765         1   \n",
       "696         8.523760           32  cross_entropy       87365         2   \n",
       "\n",
       "      test_mae  test_mae_ci_max  test_mae_ci_min  train_mae  train_mae_ci_max  \\\n",
       "1335  0.705675         0.715066         0.696186   0.644559          0.649075   \n",
       "1623  0.706800         0.717600         0.695550   0.650412          0.655600   \n",
       "711   0.707273         0.716730         0.697811   0.655483          0.660003   \n",
       "1374  0.708352         0.717835         0.698841   0.525622          0.529929   \n",
       "544   0.708500         0.719450         0.697350   0.626675          0.631763   \n",
       "1115  0.709085         0.718462         0.699818   0.626380          0.630724   \n",
       "724   0.711450         0.722350         0.700450   0.609675          0.614862   \n",
       "1826  0.711550         0.722600         0.700400   0.587337          0.592375   \n",
       "1725  0.712600         0.723050         0.701700   0.628150          0.633075   \n",
       "827   0.712825         0.721628         0.704040   0.627447          0.631495   \n",
       "1077  0.713450         0.724450         0.702150   0.649513          0.655000   \n",
       "831   0.713900         0.725250         0.702700   0.619050          0.624300   \n",
       "1265  0.713918         0.722605         0.705077   0.637722          0.641817   \n",
       "1589  0.714050         0.725150         0.702850   0.651012          0.656438   \n",
       "696   0.714150         0.724950         0.703400   0.625225          0.630337   \n",
       "\n",
       "      train_mae_ci_min use_batchnorm  \n",
       "1335          0.640063         False  \n",
       "1623          0.645200          True  \n",
       "711           0.650928          True  \n",
       "1374          0.521278         False  \n",
       "544           0.621550         False  \n",
       "1115          0.622030          True  \n",
       "724           0.604425         False  \n",
       "1826          0.582350         False  \n",
       "1725          0.623212          True  \n",
       "827           0.623340         False  \n",
       "1077          0.644150          True  \n",
       "831           0.613850         False  \n",
       "1265          0.633498         False  \n",
       "1589          0.645625         False  \n",
       "696           0.620088         False  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "def load_results_df(folder='/mnt/results'):\n",
    "    folder = Path(folder)\n",
    "    results_dicts = []\n",
    "    for p in sorted(folder.glob('**/results.json')):\n",
    "        with p.open('r') as f:\n",
    "            results_dicts.append(json.load(f))\n",
    "    return pd.DataFrame.from_dict(results_dicts)\n",
    "\n",
    "\n",
    "df = load_results_df().sort_values(by=['test_mae'], ascending=True)\n",
    "df.query('split_idx == 1 and epochs == 20').drop(\n",
    "    ['digest', 'train_mse', 'test_mse', 'epochs', 'split_idx', 'optimizer'], axis=1).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "83e91897468e411bb72bb31ad67aeeb1": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
